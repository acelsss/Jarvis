"""CLI main entry point."""
import asyncio
import os
import sys
from pathlib import Path
from typing import Optional, Any

try:
    from dotenv import load_dotenv
    # åŠ è½½ .env æ–‡ä»¶
    env_path = Path(__file__).parent.parent.parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)
except ImportError:
    pass  # python-dotenv æœªå®‰è£…æ—¶å¿½ç•¥

from core.contracts.task import (
    TASK_STATUS_NEW,
    TASK_STATUS_CONTEXT_BUILT,
    TASK_STATUS_PLANNED,
    TASK_STATUS_WAITING_APPROVAL,
    TASK_STATUS_APPROVED,
    TASK_STATUS_RUNNING,
    TASK_STATUS_COMPLETED,
)
from core.orchestrator.task_manager import TaskManager
from core.orchestrator.planner import Planner
from core.orchestrator.approval_gate import ApprovalGate
from core.orchestrator.executor import Executor
from core.orchestrator.qa_handler import handle_qa
from core.context_engine.build_context import build_context, search_openmemory
from core.router.route import route_task, route_llm_first
from core.llm.factory import build_llm_client
from core.platform.audit import AuditLogger
from core.platform.config import Config
from core.capabilities.index_builder import build_capability_index
from tools.registry import ToolRegistry
from tools.runner import ToolRunner
from tools.local.shell_tool import ShellTool
from tools.local.file_tool import FileTool
from tools.python_run import PythonRunTool
from pathlib import Path
from skills.registry import SkillsRegistry
from skills.runtime.to_plan import skill_to_plan
from core.session.history import SessionHistoryBuffer


async def process_single_task(
    description: str,
    task_manager: TaskManager,
    planner: Planner,
    approval_gate: ApprovalGate,
    executor: Executor,
    audit_logger: AuditLogger,
    tool_registry: ToolRegistry,
    tool_runner: ToolRunner,
    skills_registry: SkillsRegistry,
    sandbox_root: str,
    llm_client: Any,
    llm_router_enabled: bool,
    llm_planner_enabled: bool,
    session_history: SessionHistoryBuffer,
) -> Optional[str]:
    """å¤„ç†å•è½®ä»»åŠ¡ï¼Œè¿”å›å¯¹ç”¨æˆ·å¯è§çš„å›å¤æ–‡æœ¬ï¼ˆç”¨äº QA æ¨¡å¼ï¼‰æˆ– Noneï¼ˆç”¨äºæ‰§è¡Œæ¨¡å¼ï¼‰ã€‚"""
    if not description:
        print("é”™è¯¯: ä»»åŠ¡æè¿°ä¸èƒ½ä¸ºç©º")
        return None
    
    # åœ¨æ‰§è¡Œé“¾è·¯å‰å…ˆè®°å½• user è¾“å…¥
    session_history.add_user(description)
    chat_history_messages = session_history.get_window()
    
    print(f"\n[1/8] æ¥æ”¶ä»»åŠ¡: {description}")
    
    # 2. åˆ›å»ºä»»åŠ¡
    task = task_manager.create_task(description)
    task.update_status(TASK_STATUS_NEW)
    audit_logger.log("task_created", {
        "task_id": task.task_id,
        "description": description,
        "status": task.status,
    })
    print(f"[2/8] ä»»åŠ¡å·²åˆ›å»º: {task.task_id}")
    
    # 3. Context Engine æ„å»ºä¸Šä¸‹æ–‡
    print("[3/8] æ„å»ºä¸Šä¸‹æ–‡...")
    openmemory_results = await search_openmemory(description, top_k=3)
    context = build_context(task, openmemory_results=openmemory_results)
    task.context = context
    task.update_status(TASK_STATUS_CONTEXT_BUILT)
    task_manager.update_task(task)  # ä¿å­˜å¿«ç…§
    audit_logger.log("context_built", {
        "task_id": task.task_id,
        "openmemory_results_count": len(openmemory_results),
    })
    print(f"  - èº«ä»½é…ç½®å·²åŠ è½½")
    print(f"  - OpenMemory æœç´¢ç»“æœ: {len(openmemory_results)} æ¡")
    
    def _risk_rank(value: str) -> int:
        rank_map = {"R0": 0, "R1": 1, "R2": 2, "R3": 3}
        return rank_map.get((value or "").upper(), 2)

    def _enforce_min_risk(plan, min_risk: str) -> None:
        if not min_risk:
            return
        min_rank = _risk_rank(min_risk)
        for step in plan.steps:
            if _risk_rank(step.risk_level) < min_rank:
                step.risk_level = min_risk

    def _load_skill_fulltext(skill_id: str) -> str:
        # æ ¹æ®æ¸è¿›å¼åŠ è½½åŸåˆ™ï¼šåªåŠ è½½ SKILL.mdï¼Œä¸è‡ªåŠ¨åŠ è½½å¼•ç”¨æ–‡ä»¶
        # LLM å¯ä»¥æ ¹æ® SKILL.md ä¸­çš„æç¤ºï¼Œåœ¨éœ€è¦æ—¶é€šè¿‡æ–‡ä»¶å·¥å…·è¯»å–å¼•ç”¨æ–‡ä»¶
        fulltext = skills_registry.load_skill_fulltext(skill_id, include_references=False)
        audit_logger.log("skill.loaded", {
            "skill_id": skill_id,
            "bytes_loaded": len(fulltext.encode("utf-8")),
            "progressive_disclosure": True,  # æ ‡è®°ä½¿ç”¨äº†æ¸è¿›å¼åŠ è½½
        })
        return fulltext

    # 4. Router è·¯ç”±
    print("[4/8] è·¯ç”±ä»»åŠ¡...")
    available_tools = tool_registry.list_all()
    available_skills = skills_registry.list_all()

    route_decision = None
    matched_skill = None
    routed_tools = []
    skill_fulltext = ""
    use_planner_for_skill = False

    if llm_router_enabled and llm_client:
        capability_index = build_capability_index(skills_registry, tool_registry)
        route_decision = route_llm_first(
            task.description,
            context,
            capability_index,
            llm_client,
            audit_logger=audit_logger,
            chat_history_messages=chat_history_messages,
        )

        if route_decision.get("fallback_to_rule"):
            matched_skill, routed_tools = route_task(
                task, 
                available_tools, 
                available_skills,
                llm_client=llm_client,
                audit_logger=audit_logger,
                chat_history_messages=chat_history_messages,
            )
        else:
            route_type = route_decision.get("route_type")
            if route_type == "skill":
                skill_id = route_decision.get("skill_id")
                matched_skill = available_skills.get(skill_id)
                if not matched_skill:
                    matched_skill, routed_tools = route_task(
                        task, 
                        available_tools, 
                        available_skills,
                        llm_client=llm_client,
                        audit_logger=audit_logger,
                        chat_history_messages=chat_history_messages,
                    )
                else:
                    skill_fulltext = _load_skill_fulltext(matched_skill.skill_id)
                    # å¦‚æœå¯ç”¨äº† LLM plannerï¼Œä½¿ç”¨ LLM æ¥ç”Ÿæˆè®¡åˆ’ï¼ˆèƒ½ç†è§£æŠ€èƒ½æ–‡æ¡£å¹¶ç”Ÿæˆå®é™…å†…å®¹ï¼‰
                    # å¦åˆ™ä½¿ç”¨ skill_to_planï¼ˆè§£ææ‰§è¡Œæ­¥éª¤ä½†åªèƒ½ç”Ÿæˆå ä½æ–‡ä»¶ï¼‰
                    use_planner_for_skill = llm_planner_enabled
            elif route_type in ("tool", "mcp"):
                tool_ids = route_decision.get("tool_ids") or []
                routed_tools = [
                    tool_id
                    for tool_id in tool_ids
                    if tool_id in available_tools or (isinstance(tool_id, str) and tool_id.startswith("mcp."))
                ]
                if not routed_tools:
                    matched_skill, routed_tools = route_task(
                        task, 
                        available_tools, 
                        available_skills,
                        llm_client=llm_client,
                        audit_logger=audit_logger,
                        chat_history_messages=chat_history_messages,
                    )
            elif route_type == "qa":
                print("\nè¿›å…¥é—®ç­”æ¨¡å¼ï¼Œä¸è¿›å…¥è§„åˆ’ä¸æ‰§è¡Œã€‚")
                answer = handle_qa(
                    task.description,
                    context,
                    llm_client,
                    audit_logger=audit_logger,
                    chat_history_messages=chat_history_messages,
                )
                task.update_status(TASK_STATUS_COMPLETED)
                task_manager.update_task(task, extra_info={"qa_answer": answer})
                audit_logger.log("task_completed", {
                    "task_id": task.task_id,
                    "qa": True,
                })
                print(f"\nå›ç­”:\n{answer}")
                # è®°å½•åŠ©æ‰‹å›å¤åˆ°å†å²
                session_history.add_assistant(answer)
                return answer
            elif route_type == "clarify":
                print("\néœ€è¦æ¾„æ¸…ï¼Œä¸è¿›å…¥è§„åˆ’ä¸æ‰§è¡Œã€‚")
                questions = route_decision.get("clarify_questions") or []
                if questions:
                    print("æ¾„æ¸…é—®é¢˜ï¼š")
                    for q in questions:
                        print(f"- {q}")
                # å°†æ¾„æ¸…é—®é¢˜ä½œä¸ºåŠ©æ‰‹å›å¤è®°å½•
                clarify_text = "éœ€è¦æ¾„æ¸…ï¼š\n" + "\n".join(f"- {q}" for q in questions)
                session_history.add_assistant(clarify_text)
                return None
            else:
                matched_skill, routed_tools = route_task(
                    task, 
                    available_tools, 
                    available_skills,
                    llm_client=llm_client,
                    audit_logger=audit_logger,
                    chat_history_messages=chat_history_messages,
                )
    else:
        matched_skill, routed_tools = route_task(
            task, 
            available_tools, 
            available_skills,
            llm_client=llm_client,
            audit_logger=audit_logger,
            chat_history_messages=chat_history_messages,
        )
    
    if matched_skill:
        print(f"  - åŒ¹é…åˆ°æŠ€èƒ½: {matched_skill.name} ({matched_skill.skill_id})")
        print(f"  - æŠ€èƒ½æè¿°: {matched_skill.description}")
    else:
        print(f"  - è·¯ç”±åˆ°å·¥å…·: {', '.join(routed_tools)}")
    
    # 5. Planner ç”Ÿæˆè®¡åˆ’
    print("[5/8] ç”Ÿæˆæ‰§è¡Œè®¡åˆ’...")
    if matched_skill:
        if not skill_fulltext:
            skill_fulltext = _load_skill_fulltext(matched_skill.skill_id)
        # å¦‚æœå¯ç”¨äº† LLM plannerï¼Œä¼˜å…ˆä½¿ç”¨ LLM æ¥ç”Ÿæˆè®¡åˆ’ï¼ˆèƒ½ç†è§£æŠ€èƒ½æ–‡æ¡£å¹¶ç”Ÿæˆå®é™…å†…å®¹ï¼‰
        # å¦åˆ™ä½¿ç”¨ skill_to_planï¼ˆè§£ææ‰§è¡Œæ­¥éª¤ä½†åªèƒ½ç”Ÿæˆå ä½æ–‡ä»¶ï¼‰
        if llm_planner_enabled and llm_client:
            plan = await planner.create_plan(
                task,
                available_tools,
                routed_tools,
                skill_fulltext=skill_fulltext,
                llm_client=llm_client,
                audit_logger=audit_logger,
                chat_history_messages=chat_history_messages,
            )
            plan.source = f"skill:{matched_skill.skill_id}"
        else:
            # ä½¿ç”¨æŠ€èƒ½ç”Ÿæˆè®¡åˆ’ï¼ˆä¿æŒå…¼å®¹ï¼‰
            if skill_fulltext:
                matched_skill.instructions_md = skill_fulltext
            plan = skill_to_plan(matched_skill, task.task_id, sandbox_root)
            plan.source = f"skill:{matched_skill.skill_id}"
    else:
        # ä½¿ç”¨é»˜è®¤ Planner
        plan = await planner.create_plan(
            task,
            available_tools,
            routed_tools,
            llm_client=llm_client if llm_planner_enabled else None,
            audit_logger=audit_logger,
            chat_history_messages=chat_history_messages,
        )

    if route_decision:
        _enforce_min_risk(plan, route_decision.get("min_risk"))
    
    task.update_status(TASK_STATUS_PLANNED)
    # ä¿å­˜å¿«ç…§ï¼ˆåŒ…å« plan å’Œ skill_idï¼‰
    task_manager.update_task(task, extra_info={
        "plan": plan,
        "skill_id": matched_skill.skill_id if matched_skill else None,
        "routed_tools": routed_tools,
    })
    audit_logger.log("plan_created", {
        "task_id": task.task_id,
        "plan_id": plan.plan_id,
        "steps_count": len(plan.steps),
        "source": plan.source,
    })
    print(f"  - è®¡åˆ’ID: {plan.plan_id}")
    print(f"  - è®¡åˆ’æ¥æº: {plan.source or 'planner'}")
    print(f"  - æ­¥éª¤æ•°: {len(plan.steps)}")
    for i, step in enumerate(plan.steps, 1):
        print(f"    {i}. {step.tool_id} - {step.description} (é£é™©: {step.risk_level})")
    
    # 6. Risk Gate é£é™©è¯„ä¼°
    print("[6/8] é£é™©è¯„ä¼°...")
    risk_assessment = approval_gate.assess_plan_risk(plan.steps)
    print(f"  - é£é™©ç­‰çº§: {risk_assessment.risk_level}")
    print(f"  - éœ€è¦å®¡æ‰¹: {risk_assessment.requires_approval}")
    
    approval = None
    if risk_assessment.is_approval_required():
        task.update_status(TASK_STATUS_WAITING_APPROVAL)
        task_manager.update_task(task, extra_info={"plan": plan})  # ä¿å­˜å¿«ç…§
        audit_logger.log("waiting_approval", {
            "task_id": task.task_id,
            "risk_level": risk_assessment.risk_level,
            "reason": risk_assessment.reason,
        })
        
        # CLI ç”¨æˆ·å®¡æ‰¹
        while True:
            user_input = input(f"\nâš ï¸  æ£€æµ‹åˆ°é£é™©ç­‰çº§ {risk_assessment.risk_level}ï¼Œéœ€è¦å®¡æ‰¹ã€‚æ˜¯å¦æ‰¹å‡†æ‰§è¡Œ? (yes/no): ").strip().lower()
            if user_input in ("yes", "y"):
                approval = approval_gate.approve(task.task_id, approved=True, approver="user")
                task.update_status(TASK_STATUS_APPROVED)
                task_manager.update_task(task, extra_info={"plan": plan, "approval": approval})  # ä¿å­˜å¿«ç…§
                audit_logger.log("task_approved", {
                    "approval_id": approval.approval_id,
                    "task_id": task.task_id,
                    "approver": approval.approver,
                })
                print("âœ“ å·²æ‰¹å‡†")
                break
            elif user_input in ("no", "n"):
                approval = approval_gate.approve(task.task_id, approved=False, approver="user")
                task_manager.update_task(task, extra_info={"plan": plan, "approval": approval})  # ä¿å­˜å¿«ç…§
                audit_logger.log("task_rejected", {
                    "approval_id": approval.approval_id,
                    "task_id": task.task_id,
                    "approver": approval.approver,
                })
                print("âœ— å·²æ‹’ç»ï¼Œä»»åŠ¡ç»ˆæ­¢")
                return None
            else:
                print("è¯·è¾“å…¥ yes æˆ– no")
    else:
        # è‡ªåŠ¨æ‰¹å‡†ä½é£é™©ä»»åŠ¡
        approval = approval_gate.approve(task.task_id, approved=True, approver="system")
        task.update_status(TASK_STATUS_APPROVED)
        task_manager.update_task(task, extra_info={"plan": plan, "approval": approval})  # ä¿å­˜å¿«ç…§
        audit_logger.log("task_auto_approved", {
            "approval_id": approval.approval_id,
            "task_id": task.task_id,
            "risk_level": risk_assessment.risk_level,
        })
        print("  - è‡ªåŠ¨æ‰¹å‡†ï¼ˆä½é£é™©ï¼‰")
    
    # 7. æ‰§è¡Œå·¥å…·
    print("\n[7/8] æ‰§è¡Œå·¥å…·...")
    task.update_status(TASK_STATUS_RUNNING)
    audit_logger.log("task_started", {"task_id": task.task_id})
    
    executed_tools = []
    for i, step in enumerate(plan.steps, 1):
        print(f"\n  æ­¥éª¤ {i}/{len(plan.steps)}: {step.tool_id}")
        print(f"    æè¿°: {step.description}")
        
        tool = tool_registry.get(step.tool_id)
        if not tool:
            if step.tool_id.startswith("mcp."):
                print(f"    âœ— é”™è¯¯: {step.tool_id} æœªæ¥å…¥ MCP client")
                tool_result = tool_runner.run_missing_mcp(step.tool_id, step.step_id)
                audit_logger.log("mcp.missing_client", {
                    "task_id": task.task_id,
                    "step_id": step.step_id,
                    "tool_id": step.tool_id,
                })
            else:
                print(f"    âœ— é”™è¯¯: å·¥å…· {step.tool_id} æœªæ‰¾åˆ°")
                continue
        else:
            # æ‰§è¡Œå·¥å…·
            tool_result = await tool_runner.run(tool, step.step_id, step.params)
        
        if tool_result.success:
            print(f"    âœ“ æ‰§è¡ŒæˆåŠŸ")
            executed_tools.append(step.tool_id)
            
            # è®°å½•åŠ¨ä½œ
            task.add_action({
                "step_id": step.step_id,
                "tool_id": step.tool_id,
                "description": step.description,
                "success": True,
                "result": tool_result.result,
            })
            
            # æ”¶é›†äº§ç‰©
            if tool_result.evidence_refs:
                for ref in tool_result.evidence_refs:
                    task.add_artifact(ref)
                    print(f"    ğŸ“„ äº§ç‰©: {ref}")
            
            # ç‰¹æ®Šå¤„ç†ï¼špython_run å·¥å…·çš„å®¡è®¡æ—¥å¿—
            if step.tool_id == "python_run":
                result = tool_result.result
                meta = result.get("meta", {})
                artifacts_changed = result.get("artifacts_changed", [])
                artifacts_count = meta.get("artifacts_count", len(artifacts_changed))
                
                # å–å‰ 20 ä¸ªäº§ç‰©è·¯å¾„ä½œä¸ºæ ·æœ¬
                artifacts_sample = [
                    item["path"] for item in artifacts_changed[:20]
                ]
                
                audit_logger.log("tool.python_run", {
                    "task_id": task.task_id,
                    "step_id": step.step_id,
                    "script_path_relative": meta.get("script_path", ""),
                    "args": meta.get("args", []),
                    "cwd": meta.get("cwd", str(sandbox_root)),
                    "timeout_seconds": meta.get("timeout_seconds", 60),
                    "exit_code": result.get("exit_code", -1),
                    "stdout_len": len(result.get("stdout_excerpt", "")),
                    "stderr_len": len(result.get("stderr_excerpt", "")),
                    "duration_ms": meta.get("duration_ms", 0),
                    "artifacts_count": artifacts_count,
                    "artifacts_sample": artifacts_sample,
                })
            else:
                audit_logger.log("tool_executed", {
                    "task_id": task.task_id,
                    "step_id": step.step_id,
                    "tool_id": step.tool_id,
                    "success": True,
                    "evidence_refs": tool_result.evidence_refs,
                })
        else:
            print(f"    âœ— æ‰§è¡Œå¤±è´¥: {tool_result.error}")
            task.add_action({
                "step_id": step.step_id,
                "tool_id": step.tool_id,
                "description": step.description,
                "success": False,
                "error": tool_result.error,
            })
            audit_logger.log("tool_executed", {
                "task_id": task.task_id,
                "step_id": step.step_id,
                "tool_id": step.tool_id,
                "success": False,
                "error": tool_result.error,
            })
    
    # 8. ä»»åŠ¡å®Œæˆ
    task.update_status(TASK_STATUS_COMPLETED)
    # ä¿å­˜æœ€ç»ˆå¿«ç…§ï¼ˆåŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
    task_manager.update_task(task, extra_info={
        "plan": plan,
        "skill_id": matched_skill.skill_id if matched_skill else None,
        "routed_tools": routed_tools,
        "approval": approval,
    })
    audit_logger.log("task_completed", {
        "task_id": task.task_id,
        "artifacts": task.artifacts,
        "executed_tools": executed_tools,
    })
    
    # è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 60)
    print("[8/8] ä»»åŠ¡å®Œæˆæ€»ç»“")
    print("=" * 60)
    print(f"ä»»åŠ¡ID: {task.task_id}")
    print(f"çŠ¶æ€: {task.status}")
    print(f"æ‰§è¡Œçš„å·¥å…·: {', '.join(executed_tools) if executed_tools else 'æ— '}")
    
    # æ”¶é›† python_run å·¥å…·çš„äº§ç‰©
    python_run_artifacts = []
    for action in task.actions:
        if action.get("tool_id") == "python_run":
            result = action.get("result", {})
            artifacts = result.get("artifacts_changed", [])
            python_run_artifacts.extend(artifacts)
    
    # å±•ç¤ºäº§ç‰©è·¯å¾„
    print(f"äº§ç‰©è·¯å¾„:")
    if python_run_artifacts:
        # ä¼˜å…ˆå±•ç¤º python_run çš„äº§ç‰©ï¼ˆè‡³å°‘å‰ 10 ä¸ªï¼‰
        print(f"  (python_run å·¥å…·ï¼Œå…± {len(python_run_artifacts)} ä¸ª):")
        for i, artifact in enumerate(python_run_artifacts[:10], 1):
            kind_icon = "â•" if artifact.get("kind") == "added" else "ğŸ“"
            print(f"    {i}. {kind_icon} {artifact.get('path')} ({artifact.get('size', 0)} å­—èŠ‚)")
        if len(python_run_artifacts) > 10:
            print(f"    ... è¿˜æœ‰ {len(python_run_artifacts) - 10} ä¸ªäº§ç‰©æœªæ˜¾ç¤º")
    elif task.artifacts:
        # å…¶ä»–å·¥å…·çš„äº§ç‰©
        for artifact in task.artifacts:
            print(f"  - {artifact}")
    else:
        print("  - æ— ")
    print(f"å®¡æ‰¹è®°å½•: {approval.approval_id if approval else 'æ— '}")
    print(f"å®¡è®¡æ—¥å¿—: memory/raw_logs/audit.log.jsonl")
    print("=" * 60)
    
    # ç”Ÿæˆå¯¹ç”¨æˆ·å¯è§çš„æ€»ç»“æ–‡æœ¬ï¼Œç”¨äºè®°å½•åˆ°å†å²
    summary_text = f"ä»»åŠ¡å·²å®Œæˆã€‚æ‰§è¡Œçš„å·¥å…·: {', '.join(executed_tools) if executed_tools else 'æ— '}"
    if python_run_artifacts:
        summary_text += f"\näº§ç‰©: {len(python_run_artifacts)} ä¸ªæ–‡ä»¶"
    session_history.add_assistant(summary_text)
    
    return None


def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯ã€‚"""
    print("\n" + "=" * 60)
    print("å¯ç”¨å‘½ä»¤:")
    print("=" * 60)
    print("  /exit æˆ– /quit  - é€€å‡ºç¨‹åº")
    print("  /help           - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
    print("  /skills         - åˆ—å‡ºæ‰€æœ‰å¯ç”¨æŠ€èƒ½")
    print("  /reset          - æ¸…ç©ºå½“å‰ä¼šè¯çš„å¯¹è¯å†å²")
    print("=" * 60 + "\n")


def print_skills(skills_registry: SkillsRegistry):
    """æ‰“å°æŠ€èƒ½åˆ—è¡¨ã€‚"""
    print("\n" + "=" * 60)
    print("å·²åŠ è½½çš„æŠ€èƒ½åˆ—è¡¨")
    print("=" * 60)
    skills = skills_registry.list_all()
    if not skills:
        print("æš‚æ— å·²åŠ è½½çš„æŠ€èƒ½")
    else:
        for skill_id, skill in skills.items():
            print(f"\næŠ€èƒ½ID: {skill_id}")
            print(f"  åç§°: {skill.name}")
            print(f"  æè¿°: {skill.description}")
            print(f"  æ ‡ç­¾: {', '.join(skill.tags) if skill.tags else 'æ— '}")
            if skill.file_path:
                print(f"  è·¯å¾„: {skill.file_path}")
            # æ˜¾ç¤ºè„šæœ¬åˆ—è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
            if skill.metadata and 'discovered_files' in skill.metadata:
                scripts = skill.metadata['discovered_files'].get('scripts', [])
                if scripts:
                    print(f"  è„šæœ¬: {len(scripts)} ä¸ª")
                    for script_path in scripts[:5]:  # æœ€å¤šæ˜¾ç¤º 5 ä¸ª
                        script_name = Path(script_path).name
                        print(f"    - {script_name}")
                    if len(scripts) > 5:
                        print(f"    ... è¿˜æœ‰ {len(scripts) - 5} ä¸ªè„šæœ¬")
    print("\n" + "=" * 60 + "\n")


async def main():
    """ä¸»å‡½æ•° - REPL æ¨¡å¼ï¼Œå¸¸é©»åœ¨çº¿ã€‚"""
    # æ‰“å° bannerï¼ˆä»…ä¸€æ¬¡ï¼‰
    print("=" * 60)
    print("Jarvis v0.1 - Kernel MVP (REPL Mode)")
    print("=" * 60)
    print("è¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤\n")
    
    # åˆå§‹åŒ–ç»„ä»¶
    config = Config()
    preferences = config.load_yaml("preferences.yaml")
    sandbox_root = preferences.get("sandbox", {}).get("sandbox_root", "./sandbox")
    
    task_manager = TaskManager()
    planner = Planner(sandbox_root=sandbox_root)
    approval_gate = ApprovalGate()
    executor = Executor()
    audit_logger = AuditLogger()
    tool_registry = ToolRegistry()
    tool_runner = ToolRunner()
    
    # åˆå§‹åŒ–æŠ€èƒ½æ³¨å†Œè¡¨
    skills_registry = SkillsRegistry(workspace_dir="./skills_workspace")
    skills_registry.scan_workspace()
    
    # æ³¨å†Œå·¥å…·
    file_tool = FileTool(sandbox_root=sandbox_root)
    shell_tool = ShellTool()
    python_run_tool = PythonRunTool()
    tool_registry.register(file_tool)
    tool_registry.register(shell_tool)
    tool_registry.register(python_run_tool)
    
    # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    llm_client = None
    llm_router_enabled = os.getenv("LLM_ENABLE_ROUTER") == "1"
    llm_planner_enabled = os.getenv("LLM_ENABLE_PLANNER") == "1"
    if llm_router_enabled or llm_planner_enabled:
        llm_client = build_llm_client()
        if llm_client is None:
            llm_router_enabled = False
            llm_planner_enabled = False
    
    # åˆå§‹åŒ–ä¼šè¯å†å²ç¼“å†²åŒº
    session_history = SessionHistoryBuffer()
    
    # REPL å¾ªç¯
    while True:
        try:
            # è¯»å–ç”¨æˆ·è¾“å…¥
            user_input = input("> ").strip()
            
            # å¤„ç†ç©ºè¾“å…¥
            if not user_input:
                continue
            
            # å¤„ç†å‘½ä»¤
            if user_input in ("/exit", "/quit"):
                print("å†è§ï¼")
                break
            elif user_input == "/help":
                print_help()
                continue
            elif user_input == "/skills":
                print_skills(skills_registry)
                continue
            elif user_input == "/reset":
                session_history.reset()
                print("âœ“ å¯¹è¯å†å²å·²æ¸…ç©º")
                continue
            
            # å¤„ç†å•è½®ä»»åŠ¡
            try:
                await process_single_task(
                    description=user_input,
                    task_manager=task_manager,
                    planner=planner,
                    approval_gate=approval_gate,
                    executor=executor,
                    audit_logger=audit_logger,
                    tool_registry=tool_registry,
                    tool_runner=tool_runner,
                    skills_registry=skills_registry,
                    sandbox_root=sandbox_root,
                    llm_client=llm_client,
                    llm_router_enabled=llm_router_enabled,
                    llm_planner_enabled=llm_planner_enabled,
                    session_history=session_history,
                )
            except Exception as e:
                print(f"\nâœ— å¤„ç†ä»»åŠ¡æ—¶å‡ºé”™: {e}")
                import traceback
                if os.getenv("DEBUG") == "1":
                    traceback.print_exc()
                # å³ä½¿å‡ºé”™ä¹Ÿç»§ç»­ä¸‹ä¸€è½®
                continue
                
        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡º...")
            break
        except EOFError:
            print("\n\nå†è§ï¼")
            break
        except Exception as e:
            print(f"\nâœ— å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
            import traceback
            if os.getenv("DEBUG") == "1":
                traceback.print_exc()
            # ç»§ç»­ä¸‹ä¸€è½®ï¼Œä¸é€€å‡º
            continue
    


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\né”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
