"""CLI main entry point."""
import asyncio
import os
import sys
from pathlib import Path
from typing import Optional

try:
    from dotenv import load_dotenv
    # åŠ è½½ .env æ–‡ä»¶
    env_path = Path(__file__).parent.parent.parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)
except ImportError:
    pass  # python-dotenv æœªå®‰è£…æ—¶å¿½ç•¥

from core.contracts.task import (
    TASK_STATUS_NEW,
    TASK_STATUS_CONTEXT_BUILT,
    TASK_STATUS_PLANNED,
    TASK_STATUS_WAITING_APPROVAL,
    TASK_STATUS_APPROVED,
    TASK_STATUS_RUNNING,
    TASK_STATUS_COMPLETED,
)
from core.orchestrator.task_manager import TaskManager
from core.orchestrator.planner import Planner
from core.orchestrator.approval_gate import ApprovalGate
from core.orchestrator.executor import Executor
from core.orchestrator.qa_handler import handle_qa
from core.context_engine.build_context import build_context, search_openmemory
from core.router.route import route_task, route_llm_first
from core.llm.factory import build_llm_client
from core.platform.audit import AuditLogger
from core.platform.config import Config
from core.capabilities.index_builder import build_capability_index
from tools.registry import ToolRegistry
from tools.runner import ToolRunner
from tools.local.shell_tool import ShellTool
from tools.local.file_tool import FileTool
from tools.python_run import PythonRunTool
from skills.registry import SkillsRegistry
from skills.runtime.to_plan import skill_to_plan


async def main():
    """ä¸»å‡½æ•° - Kernel MVP æœ€å°é—­ç¯ã€‚"""
    print("=" * 60)
    print("Jarvis v0.1 - Kernel MVP")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç»„ä»¶
    config = Config()
    preferences = config.load_yaml("preferences.yaml")
    sandbox_root = preferences.get("sandbox", {}).get("sandbox_root", "./sandbox")
    
    task_manager = TaskManager()
    planner = Planner(sandbox_root=sandbox_root)
    approval_gate = ApprovalGate()
    executor = Executor()
    audit_logger = AuditLogger()
    tool_registry = ToolRegistry()
    tool_runner = ToolRunner()
    
    # åˆå§‹åŒ–æŠ€èƒ½æ³¨å†Œè¡¨
    skills_registry = SkillsRegistry(workspace_dir="./skills_workspace")
    skills_registry.scan_workspace()
    
    # æ³¨å†Œå·¥å…·
    file_tool = FileTool(sandbox_root=sandbox_root)
    shell_tool = ShellTool()
    python_run_tool = PythonRunTool()
    tool_registry.register(file_tool)
    tool_registry.register(shell_tool)
    tool_registry.register(python_run_tool)
    
    # 1. CLI è¾“å…¥
    if len(sys.argv) > 1:
        description = " ".join(sys.argv[1:])
    else:
        description = input("\nè¯·è¾“å…¥ä»»åŠ¡æè¿° (è¾“å…¥ /skills æŸ¥çœ‹å¯ç”¨æŠ€èƒ½): ").strip()
    
    # å¤„ç†ç‰¹æ®Šå‘½ä»¤
    if description == "/skills":
        print("\n" + "=" * 60)
        print("å·²åŠ è½½çš„æŠ€èƒ½åˆ—è¡¨")
        print("=" * 60)
        skills = skills_registry.list_all()
        if not skills:
            print("æš‚æ— å·²åŠ è½½çš„æŠ€èƒ½")
        else:
            for skill_id, skill in skills.items():
                print(f"\næŠ€èƒ½ID: {skill_id}")
                print(f"  åç§°: {skill.name}")
                print(f"  æè¿°: {skill.description}")
                print(f"  æ ‡ç­¾: {', '.join(skill.tags) if skill.tags else 'æ— '}")
                if skill.file_path:
                    print(f"  è·¯å¾„: {skill.file_path}")
        print("\n" + "=" * 60)
        return
    
    if not description:
        print("é”™è¯¯: ä»»åŠ¡æè¿°ä¸èƒ½ä¸ºç©º")
        return
    
    print(f"\n[1/8] æ¥æ”¶ä»»åŠ¡: {description}")
    
    # 2. åˆ›å»ºä»»åŠ¡
    task = task_manager.create_task(description)
    task.update_status(TASK_STATUS_NEW)
    audit_logger.log("task_created", {
        "task_id": task.task_id,
        "description": description,
        "status": task.status,
    })
    print(f"[2/8] ä»»åŠ¡å·²åˆ›å»º: {task.task_id}")
    
    # 3. Context Engine æ„å»ºä¸Šä¸‹æ–‡
    print("[3/8] æ„å»ºä¸Šä¸‹æ–‡...")
    openmemory_results = await search_openmemory(description, top_k=3)
    context = build_context(task, openmemory_results=openmemory_results)
    task.context = context
    task.update_status(TASK_STATUS_CONTEXT_BUILT)
    task_manager.update_task(task)  # ä¿å­˜å¿«ç…§
    audit_logger.log("context_built", {
        "task_id": task.task_id,
        "openmemory_results_count": len(openmemory_results),
    })
    print(f"  - èº«ä»½é…ç½®å·²åŠ è½½")
    print(f"  - OpenMemory æœç´¢ç»“æœ: {len(openmemory_results)} æ¡")
    
    def _risk_rank(value: str) -> int:
        rank_map = {"R0": 0, "R1": 1, "R2": 2, "R3": 3}
        return rank_map.get((value or "").upper(), 2)

    def _enforce_min_risk(plan, min_risk: str) -> None:
        if not min_risk:
            return
        min_rank = _risk_rank(min_risk)
        for step in plan.steps:
            if _risk_rank(step.risk_level) < min_rank:
                step.risk_level = min_risk

    def _load_skill_fulltext(skill_id: str) -> str:
        # æ ¹æ®æ¸è¿›å¼åŠ è½½åŸåˆ™ï¼šåªåŠ è½½ SKILL.mdï¼Œä¸è‡ªåŠ¨åŠ è½½å¼•ç”¨æ–‡ä»¶
        # LLM å¯ä»¥æ ¹æ® SKILL.md ä¸­çš„æç¤ºï¼Œåœ¨éœ€è¦æ—¶é€šè¿‡æ–‡ä»¶å·¥å…·è¯»å–å¼•ç”¨æ–‡ä»¶
        fulltext = skills_registry.load_skill_fulltext(skill_id, include_references=False)
        audit_logger.log("skill.loaded", {
            "skill_id": skill_id,
            "bytes_loaded": len(fulltext.encode("utf-8")),
            "progressive_disclosure": True,  # æ ‡è®°ä½¿ç”¨äº†æ¸è¿›å¼åŠ è½½
        })
        return fulltext

    # 4. Router è·¯ç”±
    print("[4/8] è·¯ç”±ä»»åŠ¡...")
    available_tools = tool_registry.list_all()
    available_skills = skills_registry.list_all()
    llm_client = None
    llm_router_enabled = os.getenv("LLM_ENABLE_ROUTER") == "1"
    llm_planner_enabled = os.getenv("LLM_ENABLE_PLANNER") == "1"
    if llm_router_enabled or llm_planner_enabled:
        llm_client = build_llm_client()
        if llm_client is None:
            llm_router_enabled = False
            llm_planner_enabled = False

    route_decision = None
    matched_skill = None
    routed_tools = []
    skill_fulltext = ""
    use_planner_for_skill = False

    if llm_router_enabled and llm_client:
        capability_index = build_capability_index(skills_registry, tool_registry)
        route_decision = route_llm_first(
            task.description,
            context,
            capability_index,
            llm_client,
            audit_logger=audit_logger,
        )

        if route_decision.get("fallback_to_rule"):
            matched_skill, routed_tools = route_task(task, available_tools, available_skills)
        else:
            route_type = route_decision.get("route_type")
            if route_type == "skill":
                skill_id = route_decision.get("skill_id")
                matched_skill = available_skills.get(skill_id)
                if not matched_skill:
                    matched_skill, routed_tools = route_task(task, available_tools, available_skills)
                else:
                    skill_fulltext = _load_skill_fulltext(matched_skill.skill_id)
                    # å¦‚æœå¯ç”¨äº† LLM plannerï¼Œä½¿ç”¨ LLM æ¥ç”Ÿæˆè®¡åˆ’ï¼ˆèƒ½ç†è§£æŠ€èƒ½æ–‡æ¡£å¹¶ç”Ÿæˆå®é™…å†…å®¹ï¼‰
                    # å¦åˆ™ä½¿ç”¨ skill_to_planï¼ˆè§£ææ‰§è¡Œæ­¥éª¤ä½†åªèƒ½ç”Ÿæˆå ä½æ–‡ä»¶ï¼‰
                    use_planner_for_skill = llm_planner_enabled
            elif route_type in ("tool", "mcp"):
                tool_ids = route_decision.get("tool_ids") or []
                routed_tools = [
                    tool_id
                    for tool_id in tool_ids
                    if tool_id in available_tools or (isinstance(tool_id, str) and tool_id.startswith("mcp."))
                ]
                if not routed_tools:
                    matched_skill, routed_tools = route_task(task, available_tools, available_skills)
            elif route_type == "qa":
                print("\nè¿›å…¥é—®ç­”æ¨¡å¼ï¼Œä¸è¿›å…¥è§„åˆ’ä¸æ‰§è¡Œã€‚")
                answer = handle_qa(
                    task.description,
                    context,
                    llm_client,
                    audit_logger=audit_logger,
                )
                task.update_status(TASK_STATUS_COMPLETED)
                task_manager.update_task(task, extra_info={"qa_answer": answer})
                audit_logger.log("task_completed", {
                    "task_id": task.task_id,
                    "qa": True,
                })
                print(f"\nå›ç­”:\n{answer}")
                return
            elif route_type == "clarify":
                print("\néœ€è¦æ¾„æ¸…ï¼Œä¸è¿›å…¥è§„åˆ’ä¸æ‰§è¡Œã€‚")
                questions = route_decision.get("clarify_questions") or []
                if questions:
                    print("æ¾„æ¸…é—®é¢˜ï¼š")
                    for q in questions:
                        print(f"- {q}")
                return
            else:
                matched_skill, routed_tools = route_task(task, available_tools, available_skills)
    else:
        matched_skill, routed_tools = route_task(task, available_tools, available_skills)
    
    if matched_skill:
        print(f"  - åŒ¹é…åˆ°æŠ€èƒ½: {matched_skill.name} ({matched_skill.skill_id})")
        print(f"  - æŠ€èƒ½æè¿°: {matched_skill.description}")
    else:
        print(f"  - è·¯ç”±åˆ°å·¥å…·: {', '.join(routed_tools)}")
    
    # 5. Planner ç”Ÿæˆè®¡åˆ’
    print("[5/8] ç”Ÿæˆæ‰§è¡Œè®¡åˆ’...")
    if matched_skill:
        if not skill_fulltext:
            skill_fulltext = _load_skill_fulltext(matched_skill.skill_id)
        # å¦‚æœå¯ç”¨äº† LLM plannerï¼Œä¼˜å…ˆä½¿ç”¨ LLM æ¥ç”Ÿæˆè®¡åˆ’ï¼ˆèƒ½ç†è§£æŠ€èƒ½æ–‡æ¡£å¹¶ç”Ÿæˆå®é™…å†…å®¹ï¼‰
        # å¦åˆ™ä½¿ç”¨ skill_to_planï¼ˆè§£ææ‰§è¡Œæ­¥éª¤ä½†åªèƒ½ç”Ÿæˆå ä½æ–‡ä»¶ï¼‰
        if llm_planner_enabled and llm_client:
            plan = await planner.create_plan(
                task,
                available_tools,
                routed_tools,
                skill_fulltext=skill_fulltext,
                llm_client=llm_client,
                audit_logger=audit_logger,
            )
            plan.source = f"skill:{matched_skill.skill_id}"
        else:
            # ä½¿ç”¨æŠ€èƒ½ç”Ÿæˆè®¡åˆ’ï¼ˆä¿æŒå…¼å®¹ï¼‰
            if skill_fulltext:
                matched_skill.instructions_md = skill_fulltext
            plan = skill_to_plan(matched_skill, task.task_id, sandbox_root)
            plan.source = f"skill:{matched_skill.skill_id}"
    else:
        # ä½¿ç”¨é»˜è®¤ Planner
        plan = await planner.create_plan(
            task,
            available_tools,
            routed_tools,
            llm_client=llm_client if llm_planner_enabled else None,
            audit_logger=audit_logger,
        )

    if route_decision:
        _enforce_min_risk(plan, route_decision.get("min_risk"))
    
    task.update_status(TASK_STATUS_PLANNED)
    # ä¿å­˜å¿«ç…§ï¼ˆåŒ…å« plan å’Œ skill_idï¼‰
    task_manager.update_task(task, extra_info={
        "plan": plan,
        "skill_id": matched_skill.skill_id if matched_skill else None,
        "routed_tools": routed_tools,
    })
    audit_logger.log("plan_created", {
        "task_id": task.task_id,
        "plan_id": plan.plan_id,
        "steps_count": len(plan.steps),
        "source": plan.source,
    })
    print(f"  - è®¡åˆ’ID: {plan.plan_id}")
    print(f"  - è®¡åˆ’æ¥æº: {plan.source or 'planner'}")
    print(f"  - æ­¥éª¤æ•°: {len(plan.steps)}")
    for i, step in enumerate(plan.steps, 1):
        print(f"    {i}. {step.tool_id} - {step.description} (é£é™©: {step.risk_level})")
    
    # 6. Risk Gate é£é™©è¯„ä¼°
    print("[6/8] é£é™©è¯„ä¼°...")
    risk_assessment = approval_gate.assess_plan_risk(plan.steps)
    print(f"  - é£é™©ç­‰çº§: {risk_assessment.risk_level}")
    print(f"  - éœ€è¦å®¡æ‰¹: {risk_assessment.requires_approval}")
    
    approval = None
    if risk_assessment.is_approval_required():
        task.update_status(TASK_STATUS_WAITING_APPROVAL)
        task_manager.update_task(task, extra_info={"plan": plan})  # ä¿å­˜å¿«ç…§
        audit_logger.log("waiting_approval", {
            "task_id": task.task_id,
            "risk_level": risk_assessment.risk_level,
            "reason": risk_assessment.reason,
        })
        
        # CLI ç”¨æˆ·å®¡æ‰¹
        while True:
            user_input = input(f"\nâš ï¸  æ£€æµ‹åˆ°é£é™©ç­‰çº§ {risk_assessment.risk_level}ï¼Œéœ€è¦å®¡æ‰¹ã€‚æ˜¯å¦æ‰¹å‡†æ‰§è¡Œ? (yes/no): ").strip().lower()
            if user_input in ("yes", "y"):
                approval = approval_gate.approve(task.task_id, approved=True, approver="user")
                task.update_status(TASK_STATUS_APPROVED)
                task_manager.update_task(task, extra_info={"plan": plan, "approval": approval})  # ä¿å­˜å¿«ç…§
                audit_logger.log("task_approved", {
                    "approval_id": approval.approval_id,
                    "task_id": task.task_id,
                    "approver": approval.approver,
                })
                print("âœ“ å·²æ‰¹å‡†")
                break
            elif user_input in ("no", "n"):
                approval = approval_gate.approve(task.task_id, approved=False, approver="user")
                task_manager.update_task(task, extra_info={"plan": plan, "approval": approval})  # ä¿å­˜å¿«ç…§
                audit_logger.log("task_rejected", {
                    "approval_id": approval.approval_id,
                    "task_id": task.task_id,
                    "approver": approval.approver,
                })
                print("âœ— å·²æ‹’ç»ï¼Œä»»åŠ¡ç»ˆæ­¢")
                return
            else:
                print("è¯·è¾“å…¥ yes æˆ– no")
    else:
        # è‡ªåŠ¨æ‰¹å‡†ä½é£é™©ä»»åŠ¡
        approval = approval_gate.approve(task.task_id, approved=True, approver="system")
        task.update_status(TASK_STATUS_APPROVED)
        task_manager.update_task(task, extra_info={"plan": plan, "approval": approval})  # ä¿å­˜å¿«ç…§
        audit_logger.log("task_auto_approved", {
            "approval_id": approval.approval_id,
            "task_id": task.task_id,
            "risk_level": risk_assessment.risk_level,
        })
        print("  - è‡ªåŠ¨æ‰¹å‡†ï¼ˆä½é£é™©ï¼‰")
    
    # 7. æ‰§è¡Œå·¥å…·
    print("\n[7/8] æ‰§è¡Œå·¥å…·...")
    task.update_status(TASK_STATUS_RUNNING)
    audit_logger.log("task_started", {"task_id": task.task_id})
    
    executed_tools = []
    for i, step in enumerate(plan.steps, 1):
        print(f"\n  æ­¥éª¤ {i}/{len(plan.steps)}: {step.tool_id}")
        print(f"    æè¿°: {step.description}")
        
        tool = tool_registry.get(step.tool_id)
        if not tool:
            if step.tool_id.startswith("mcp."):
                print(f"    âœ— é”™è¯¯: {step.tool_id} æœªæ¥å…¥ MCP client")
                tool_result = tool_runner.run_missing_mcp(step.tool_id, step.step_id)
                audit_logger.log("mcp.missing_client", {
                    "task_id": task.task_id,
                    "step_id": step.step_id,
                    "tool_id": step.tool_id,
                })
            else:
                print(f"    âœ— é”™è¯¯: å·¥å…· {step.tool_id} æœªæ‰¾åˆ°")
                continue
        else:
            # æ‰§è¡Œå·¥å…·
            tool_result = await tool_runner.run(tool, step.step_id, step.params)
        
        if tool_result.success:
            print(f"    âœ“ æ‰§è¡ŒæˆåŠŸ")
            executed_tools.append(step.tool_id)
            
            # è®°å½•åŠ¨ä½œ
            task.add_action({
                "step_id": step.step_id,
                "tool_id": step.tool_id,
                "description": step.description,
                "success": True,
                "result": tool_result.result,
            })
            
            # æ”¶é›†äº§ç‰©
            if tool_result.evidence_refs:
                for ref in tool_result.evidence_refs:
                    task.add_artifact(ref)
                    print(f"    ğŸ“„ äº§ç‰©: {ref}")
            
            # ç‰¹æ®Šå¤„ç†ï¼špython_run å·¥å…·çš„å®¡è®¡æ—¥å¿—
            if step.tool_id == "python_run":
                result = tool_result.result
                meta = result.get("meta", {})
                audit_logger.log("tool.python_run", {
                    "task_id": task.task_id,
                    "step_id": step.step_id,
                    "script_path_relative": meta.get("script_path", ""),
                    "args": meta.get("args", []),
                    "cwd": meta.get("cwd", str(sandbox_root)),
                    "timeout_seconds": meta.get("timeout_seconds", 60),
                    "exit_code": result.get("exit_code", -1),
                    "stdout_len": len(result.get("stdout_excerpt", "")),
                    "stderr_len": len(result.get("stderr_excerpt", "")),
                    "duration_ms": meta.get("duration_ms", 0),
                })
            else:
                audit_logger.log("tool_executed", {
                    "task_id": task.task_id,
                    "step_id": step.step_id,
                    "tool_id": step.tool_id,
                    "success": True,
                    "evidence_refs": tool_result.evidence_refs,
                })
        else:
            print(f"    âœ— æ‰§è¡Œå¤±è´¥: {tool_result.error}")
            task.add_action({
                "step_id": step.step_id,
                "tool_id": step.tool_id,
                "description": step.description,
                "success": False,
                "error": tool_result.error,
            })
            audit_logger.log("tool_executed", {
                "task_id": task.task_id,
                "step_id": step.step_id,
                "tool_id": step.tool_id,
                "success": False,
                "error": tool_result.error,
            })
    
    # 8. ä»»åŠ¡å®Œæˆ
    task.update_status(TASK_STATUS_COMPLETED)
    # ä¿å­˜æœ€ç»ˆå¿«ç…§ï¼ˆåŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
    task_manager.update_task(task, extra_info={
        "plan": plan,
        "skill_id": matched_skill.skill_id if matched_skill else None,
        "routed_tools": routed_tools,
        "approval": approval,
    })
    audit_logger.log("task_completed", {
        "task_id": task.task_id,
        "artifacts": task.artifacts,
        "executed_tools": executed_tools,
    })
    
    # è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 60)
    print("[8/8] ä»»åŠ¡å®Œæˆæ€»ç»“")
    print("=" * 60)
    print(f"ä»»åŠ¡ID: {task.task_id}")
    print(f"çŠ¶æ€: {task.status}")
    print(f"æ‰§è¡Œçš„å·¥å…·: {', '.join(executed_tools) if executed_tools else 'æ— '}")
    print(f"äº§ç‰©è·¯å¾„:")
    if task.artifacts:
        for artifact in task.artifacts:
            print(f"  - {artifact}")
    else:
        print("  - æ— ")
    print(f"å®¡æ‰¹è®°å½•: {approval.approval_id if approval else 'æ— '}")
    print(f"å®¡è®¡æ—¥å¿—: memory/raw_logs/audit.log.jsonl")
    print("=" * 60)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\né”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
